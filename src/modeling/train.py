import pandas as pd
import sys
import os
import joblib

# Agregamos el directorio ra√≠z al path para poder importar m√≥dulos propios
sys.path.append(os.getcwd())

from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix

# Importamos nuestro pipeline de preprocesamiento definido anteriormente
try:
    from src.modeling.pipeline import get_preprocessing_pipeline
except ImportError:
    # Fallback por si se ejecuta desde dentro de la carpeta modeling
    sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..')))
    from src.modeling.pipeline import get_preprocessing_pipeline

def train_model():
    print("üöÄ Iniciando proceso de entrenamiento del modelo CESFAM...")

    # --- 1. Carga de Datos ---
    data_path = "data/raw/dataset_cesfam_v1.csv"
    if not os.path.exists(data_path):
        raise FileNotFoundError(f"No se encontr√≥ el dataset en {data_path}. Ejecuta primero data_generator.py")
    
    df = pd.read_csv(data_path)
    print(f"‚úÖ Datos cargados: {df.shape[0]} registros.")

    # --- 2. Separaci√≥n de Variables (X) y Objetivo (y) ---
    target = 'target_no_asiste'
    X = df.drop(columns=[target, 'paciente_id']) # Eliminamos ID porque no predice nada
    y = df[target]

    # --- 3. Divisi√≥n Train/Test (Requisito R√∫brica) ---
    # Usamos 80% para entrenar y 20% para validar.
    # stratify=y asegura que la proporci√≥n de 'no-shows' sea igual en ambos grupos.
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    print(f"üîπ Datos de entrenamiento: {X_train.shape[0]}")
    print(f"üîπ Datos de prueba: {X_test.shape[0]}")

    # --- 4. Definici√≥n del Modelo y Pipeline Completo ---
    # Usamos GradientBoostingClassifier (similar a XGBoost)
    # Justificaci√≥n de Hiperpar√°metros:
    # - n_estimators=100: Cantidad de √°rboles de decisi√≥n (suficiente para este volumen).
    # - learning_rate=0.1: Paso de aprendizaje est√°ndar para evitar overfitting.
    # - max_depth=3: √Årboles poco profundos para mantener el modelo generalizable.
    model = GradientBoostingClassifier(
        n_estimators=100,
        learning_rate=0.1,
        max_depth=3,
        random_state=42
    )

    # Unimos el preprocesador (pipeline.py) con el modelo
    full_pipeline = Pipeline([
        ('preprocessor', get_preprocessing_pipeline()),
        ('classifier', model)
    ])

    # --- 5. Entrenamiento ---
    print("‚è≥ Entrenando el modelo (esto puede tardar unos segundos)...")
    full_pipeline.fit(X_train, y_train)
    print("‚úÖ Entrenamiento completado.")

    # --- 6. Evaluaci√≥n y M√©tricas (Requisito R√∫brica) ---
    print("\n--- üìä Evaluaci√≥n del Modelo (Set de Prueba) ---")
    y_pred = full_pipeline.predict(X_test)
    y_proba = full_pipeline.predict_proba(X_test)[:, 1] # Probabilidad de clase 1

    # Reporte de clasificaci√≥n (Precision, Recall, F1)
    print(classification_report(y_test, y_pred))

    # M√©trica ROC-AUC (Indica qu√© tan bueno es separando clases)
    auc = roc_auc_score(y_test, y_proba)
    print(f"üèÜ ROC-AUC Score: {auc:.4f}")

    # Matriz de Confusi√≥n
    cm = confusion_matrix(y_test, y_pred)
    tn, fp, fn, tp = cm.ravel()
    print(f"\nMatriz de Confusi√≥n:")
    print(f"Verdaderos Negativos (Asiste predicho OK): {tn}")
    print(f"Falsos Positivos (Error tipo 1): {fp}")
    print(f"Falsos Negativos (Error grave - No asiste y no avisamos): {fn}")
    print(f"Verdaderos Positivos (No asiste detectado): {tp}")

    # --- 7. Serializaci√≥n (Guardado del Modelo) ---
    model_dir = "models"
    os.makedirs(model_dir, exist_ok=True)
    model_path = os.path.join(model_dir, "model_pipeline.pkl")
    
    joblib.dump(full_pipeline, model_path)
    print(f"\nüíæ Modelo guardado exitosamente en: {model_path}")
    print("Listo para ser usado por la API.")

if __name__ == "__main__":
    train_model()